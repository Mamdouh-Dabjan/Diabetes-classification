{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5f9f53-dd63-4bd4-b6a4-fe9fb31340f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "#Preprocess the data\n",
    "numeric_col=[]\n",
    "non_numeric_col=[]\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        if(df[column].nunique()<5):\n",
    "            non_numeric_col.append(column)\n",
    "        else:\n",
    "            numeric_col.append(column)\n",
    "    else:\n",
    "        non_numeric_col.append(column)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['smoking_history'] = df['smoking_history'].replace({'not_current':'former','ever':'never'})\n",
    "for col in non_numeric_col:\n",
    "    df[col]=le.fit_transform(df[col])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4bf469-d9dd-40d3-8b5f-99059280166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diabetes']\n",
    "X = df.drop('diabetes', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc73076-75a9-4bb8-99db-e1acf22cada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0    91500\n",
       "1    91500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the SMOTE technique to account for the class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy = 'minority')\n",
    "X, y= smote.fit_resample(X,y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a758e4cd-6299-4998-b73b-0a86050d3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb9b5d-d451-4fa2-a062-3d9ddd829342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimize the model using Bayesian Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label = y_train)\n",
    "\n",
    "def bo_tune_xgb(max_depth, gamma, learning_rate, subsample):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': subsample,\n",
    "              'eval_metric': 'auc',\n",
    "             'booster': 'dart',\n",
    "             'device':'cuda'}\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=50, nfold=5)\n",
    "    return cv_result['test-auc-mean'].iloc[-1]\n",
    "\n",
    "hyperparameter_space = {'max_depth': (3, 20),\n",
    "                        'gamma': (0, 1),\n",
    "                        'learning_rate':(0.01,1),\n",
    "                       'subsample': (0.5, 0.8),\n",
    "                       }\n",
    "\n",
    "optimizer = BayesianOptimization(f=bo_tune_xgb, pbounds=hyperparameter_space, random_state=42, verbose=2)\n",
    "optimizer.maximize(init_points=5, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47416afc-7181-43ed-a2b4-850e1c5713a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     27567\n",
      "           1       0.99      0.97      0.98     27333\n",
      "\n",
      "    accuracy                           0.98     54900\n",
      "   macro avg       0.98      0.98      0.98     54900\n",
      "weighted avg       0.98      0.98      0.98     54900\n",
      "\n",
      " AUC score is : 0.9799492012629235\n"
     ]
    }
   ],
   "source": [
    "#Train the model using the optimal hyperparameters\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "params = {\n",
    "    'tree_method': 'hist',\n",
    "    'booster':'dart',\n",
    "    'objective':'binary:logistic',\n",
    "    'subsample':0.6952,\n",
    "    'eval_metric':'auc',\n",
    "    'learning_rate':0.2005,\n",
    "    'max_depth': 10,\n",
    "    'device':'cuda',\n",
    "    'gamma': 0.2125,\n",
    "    'max_depth': 12,\n",
    "    'lambda': 0,\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label = y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label = y_test)\n",
    "model = xgb.train(params, dtrain, num_boost_round = 100)\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f' AUC score is : {roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2531de7-3089-4337-854c-0689a506d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     27567\n",
      "           1       0.98      0.97      0.98     27333\n",
      "\n",
      "    accuracy                           0.98     54900\n",
      "   macro avg       0.98      0.98      0.98     54900\n",
      "weighted avg       0.98      0.98      0.98     54900\n",
      "\n",
      " AUC score is : 0.9764560923254374\n"
     ]
    }
   ],
   "source": [
    "#train the random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion='log_loss', n_estimators = 600, max_features = 'log2')\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f' AUC score is : {roc_auc_score(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
